{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHNrtkQ_chtf"
      },
      "source": [
        "# Subir archivo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "w-5P4Y9ZcgG5",
        "outputId": "c06b78df-a60b-42b9-8807-2d337d3c82d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd516f7b-e083-4e0e-b959-b31e9ce7df31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd516f7b-e083-4e0e-b959-b31e9ce7df31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.xlsx to data.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#rename to data.xlsx\n",
        "import os\n",
        "\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "os.rename(uploaded_filename, \"data.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XEFCtJrNHUt"
      },
      "source": [
        "# 1. Instalar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjBQnyorNGWI",
        "outputId": "bbcbaa89-3550-4e9e-cb31-a7330391d30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting streamlit_elements\n",
            "  Downloading streamlit_elements-0.1.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m899.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_elements-0.1.0-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit, streamlit_elements\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 streamlit_elements-0.1.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit plotly pandas streamlit_elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1AR-DbIOQ_v"
      },
      "source": [
        "# 2. Instalar local tunnels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiYny2FNOT5V",
        "outputId": "a90e9472-bb18-4773-8f67-4604a3533865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNdsTZpuNZ8h"
      },
      "source": [
        "# 3. Crear funciones necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb_5IBDUNDg0",
        "outputId": "249203e7-ae96-44f6-86a8-e29cb0c55407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "from typing import Tuple, List, Dict, Any, Optional\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.graph_objects import Figure\n",
        "\n",
        "def prepareDataTable(plot_data, is_higher_better):\n",
        "    \"\"\"Prepare data for display in a table with semaphore status.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    plot_data : pd.DataFrame\n",
        "        DataFrame with KPI, Meta, and Aceptacion columns\n",
        "    is_higher_better : bool\n",
        "        Whether higher values are better for this KPI\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Data formatted for display in a table\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying the original\n",
        "    display_data = plot_data.copy()\n",
        "\n",
        "    # Format date column if present\n",
        "    if 'Fecha' in display_data.columns:\n",
        "        display_data['Fecha'] = display_data['Fecha'].dt.strftime('%Y/%m')\n",
        "\n",
        "    # Apply function to create semaphore status\n",
        "    display_data['Estado'] = display_data.apply(\n",
        "        lambda row: getSemaphore(row, is_higher_better),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return display_data\n",
        "\n",
        "def loadData(filePath: str = \"data.xlsx\") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load data from Excel file and return the necessary dataframes.\"\"\"\n",
        "    try:\n",
        "        mediciones = pd.read_excel(filePath, sheet_name=0)\n",
        "        errores = pd.read_excel(filePath, sheet_name=1)\n",
        "        tiempoDeRespuesta = pd.read_excel(filePath, sheet_name=2)\n",
        "        disponibilidad = pd.read_excel(filePath, sheet_name=3)\n",
        "        tiquetesConErrores = pd.read_excel(filePath, sheet_name=4)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\"El archivo data.xlsx no se encuentra en la ruta especificada.\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"El archivo data.xlsx no contiene las hojas necesarias.\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error al cargar el archivo: {e}\")\n",
        "\n",
        "    try:\n",
        "        mediciones['Fecha_Inicio_Mes'] = pd.to_datetime(mediciones['Fecha_Inicio_Mes'])\n",
        "        mediciones['Fecha_Fin_Mes'] = pd.to_datetime(mediciones['Fecha_Fin_Mes'])\n",
        "        tiempoDeRespuesta['Fecha_Inicio_Mes'] = pd.to_datetime(tiempoDeRespuesta['Fecha_Inicio_Mes'])\n",
        "        tiempoDeRespuesta['Fecha_Fin_Mes'] = pd.to_datetime(tiempoDeRespuesta['Fecha_Fin_Mes'])\n",
        "        disponibilidad['Fecha_Inicio_Mes'] = pd.to_datetime(disponibilidad['Fecha_Inicio_Mes'])\n",
        "        disponibilidad['Fecha_Fin_Mes'] = pd.to_datetime(disponibilidad['Fecha_Fin_Mes'])\n",
        "    except KeyError as e:\n",
        "        raise KeyError(f\"Error al convertir columnas a datetime: {e}\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error inesperado: {e}\")\n",
        "\n",
        "    return mediciones, tiempoDeRespuesta, disponibilidad, tiquetesConErrores, errores\n",
        "\n",
        "\n",
        "def preprocessErrores(errores: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Process the errores DataFrame to add date column if needed.\"\"\"\n",
        "    if 'Fecha' not in errores.columns and 'A√±o' in errores.columns and 'Trimestre' in errores.columns:\n",
        "        # Mapear trimestres a meses (usando el primer mes de cada trimestre)\n",
        "        trimestre_a_mes = {\n",
        "            'Trim.1': 1,\n",
        "            'Trim.2': 4,\n",
        "            'Trim.3': 7,\n",
        "            'Trim.4': 10\n",
        "        }\n",
        "\n",
        "        # Crear una columna de fecha\n",
        "        errores['Fecha'] = errores.apply(\n",
        "            lambda row: pd.Timestamp(year=row['A√±o'], month=trimestre_a_mes[row['Trimestre']], day=1),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Ordenar por fecha\n",
        "        errores = errores.sort_values(['Aplicaci√≥n', 'Criticidad', 'Fecha'])\n",
        "\n",
        "    return errores\n",
        "\n",
        "\n",
        "def getSemaphore(row, higher_is_better):\n",
        "    \"\"\"Return semaphore icon based on KPI, meta and acceptance values.\"\"\"\n",
        "    kpi_value = row['KPI']\n",
        "    meta_value = row['Meta']\n",
        "    acceptance_value = row['Aceptacion']\n",
        "\n",
        "    if higher_is_better:\n",
        "        # Higher is better\n",
        "        if kpi_value >= meta_value:\n",
        "            return \"üü¢ Cumplido\"\n",
        "        elif kpi_value >= acceptance_value:\n",
        "            return \"üü° Aceptado\"\n",
        "        else:\n",
        "            return \"üî¥ Incumplido\"\n",
        "    else:\n",
        "        # Lower is better\n",
        "        if kpi_value <= meta_value:\n",
        "            return \"üü¢ Cumplido\"\n",
        "        elif kpi_value <= acceptance_value:\n",
        "            return \"üü° Aceptado\"\n",
        "        else:\n",
        "            return \"üî¥ Incumplido\"\n",
        "\n",
        "def setupFilters(mediciones):\n",
        "    \"\"\"Set up filters in sidebar and return selected values and filtered data.\"\"\"\n",
        "    services = mediciones['Aplicaci√≥n'].unique().tolist()\n",
        "\n",
        "    years = sorted(mediciones['Fecha_Inicio_Mes'].dt.year.unique().tolist())\n",
        "    months = list(range(1, 13))\n",
        "\n",
        "    st.sidebar.header(\"Dashboard de KPIs\")\n",
        "    st.sidebar.subheader(\"Filtros\")\n",
        "    selected_service = st.sidebar.selectbox(\"Seleccionar servicio\", services)\n",
        "    selected_kpi = st.sidebar.selectbox(\"Seleccionar KPI\", {\"Tiempo Respuesta\": \"Tiempo Respuesta\", \"Disponibilidad\": \"Horas_Disp_reales_mes\", \"Tiquetes con Errores\": \"Tiquetes con Errores\"})\n",
        "\n",
        "    selected_year = st.sidebar.selectbox(\"Seleccionar a√±o\", [\"Todos\"] + years)\n",
        "    selected_month = st.sidebar.selectbox(\"Seleccionar mes\", [\"Todos\"] + [f\"{m:02d}\" for m in months])\n",
        "\n",
        "    service_data = mediciones[mediciones['Aplicaci√≥n'] == selected_service]\n",
        "\n",
        "    if selected_year != \"Todos\":\n",
        "        service_data = service_data[service_data['Fecha_Inicio_Mes'].dt.year == selected_year]\n",
        "\n",
        "    if selected_month != \"Todos\":\n",
        "        selected_month_int = int(selected_month)\n",
        "        service_data = service_data[service_data['Fecha_Inicio_Mes'].dt.month == selected_month_int]\n",
        "\n",
        "    service_data = service_data.sort_values('Fecha_Inicio_Mes')\n",
        "\n",
        "    return selected_service, selected_kpi, service_data\n",
        "\n",
        "def calculateKpiValues(service_data, kpi_name, tiempoDeRespuesta, disponibilidad, tiquetesConErrores):\n",
        "    \"\"\"Calculate KPI values for the specified KPI type.\"\"\"\n",
        "    if kpi_name == \"Tiempo Respuesta\":\n",
        "        kpi_values = service_data[\"Tiempo Respuesta\"].tolist()\n",
        "        meta_values = [tiempoDeRespuesta.loc[tiempoDeRespuesta['Fecha_Inicio_Mes'] == date, 'Meta_ToR'].values[0]\n",
        "                      if date in tiempoDeRespuesta['Fecha_Inicio_Mes'].values else None\n",
        "                      for date in service_data['Fecha_Inicio_Mes']]\n",
        "        nivel_aceptable = [tiempoDeRespuesta.loc[tiempoDeRespuesta['Fecha_Inicio_Mes'] == date, 'Nivel_Aceptable'].values[0]\n",
        "                           if date in tiempoDeRespuesta['Fecha_Inicio_Mes'].values else None\n",
        "                           for date in service_data['Fecha_Inicio_Mes']]\n",
        "        y_axis_label = \"Tiempo de Respuesta\"\n",
        "\n",
        "    elif kpi_name == \"Disponibilidad\":\n",
        "        # Convert availability to percentage (multiply by 100)\n",
        "        kpi_values = ((service_data[\"Horas_Disp_reales_mes\"] /\n",
        "                      (service_data[\"Horas_Disp_Mes\"] - service_data[\"Horas_Indisp_Progr_mes\"])) * 100).tolist()\n",
        "        meta_values = [disponibilidad.loc[disponibilidad['Fecha_Inicio_Mes'] == date, 'Meta_disp'].values[0] * 100\n",
        "                      if date in disponibilidad['Fecha_Inicio_Mes'].values else None\n",
        "                      for date in service_data['Fecha_Inicio_Mes']]\n",
        "        nivel_aceptable = [disponibilidad.loc[disponibilidad['Fecha_Inicio_Mes'] == date, 'Nivel_Aceptable'].values[0] * 100\n",
        "                           if date in disponibilidad['Fecha_Inicio_Mes'].values else None\n",
        "                           for date in service_data['Fecha_Inicio_Mes']]\n",
        "        y_axis_label = \"Disponibilidad (%)\"\n",
        "\n",
        "    elif kpi_name == \"Tiquetes con Errores\":\n",
        "        kpi_values = service_data[\"Tiquetes con Errores\"].tolist()\n",
        "        current_year = service_data['Fecha_Inicio_Mes'].dt.year.iloc[0] if not service_data.empty else 2020\n",
        "        criticality = \"Alta\"\n",
        "        meta_values = [tiquetesConErrores.loc[(tiquetesConErrores['Criticidad'] == criticality) &\n",
        "                                              (tiquetesConErrores['A√±o'] == current_year), 'Meta'].values[0]\n",
        "                       if not tiquetesConErrores[(tiquetesConErrores['Criticidad'] == criticality) &\n",
        "                                                (tiquetesConErrores['A√±o'] == current_year)].empty else None]\n",
        "        nivel_aceptable = [meta_values[0]] if meta_values else [None]\n",
        "        y_axis_label = \"Numero de Tiquetes con Errores\"\n",
        "\n",
        "    return kpi_values, meta_values, nivel_aceptable, y_axis_label\n",
        "\n",
        "def calculateTCEWithErroresTable(service_data, selected_kpi, errores, selected_service, tiquetesConErrores=None, criticality=None):\n",
        "    \"\"\"Calculate ticket error KPI values using the errores table.\"\"\"\n",
        "    if selected_kpi == \"Tiquetes con Errores\":\n",
        "        # If tiquetesConErrores is not provided, default meta values will be used\n",
        "        if tiquetesConErrores is None:\n",
        "            st.warning(\"Datos de metas para tiquetes no proporcionados. Se usar√°n valores predeterminados.\")\n",
        "\n",
        "        # Filtrar los datos de errores para el servicio seleccionado\n",
        "        service_errors = errores[errores['Aplicaci√≥n'] == selected_service].sort_values('Fecha')\n",
        "\n",
        "        if service_errors.empty:\n",
        "            return [], [], [], \"Porcentaje de Tiquetes Resueltos\"\n",
        "\n",
        "        # Get date range from service_data to filter errors by date\n",
        "        if not service_data.empty:\n",
        "            # Get min and max dates from service_data\n",
        "            min_date = service_data['Fecha_Inicio_Mes'].min()\n",
        "            max_date = service_data['Fecha_Inicio_Mes'].max()\n",
        "\n",
        "            # Filter errors by date range\n",
        "            if 'Fecha' in service_errors.columns:\n",
        "                service_errors = service_errors[\n",
        "                    (service_errors['Fecha'] >= min_date) &\n",
        "                    (service_errors['Fecha'] <= max_date)\n",
        "                ]\n",
        "            elif 'A√±o' in service_errors.columns:\n",
        "                # If we only have year, filter by year\n",
        "                min_year = min_date.year\n",
        "                max_year = max_date.year\n",
        "                service_errors = service_errors[\n",
        "                    (service_errors['A√±o'] >= min_year) &\n",
        "                    (service_errors['A√±o'] <= max_year)\n",
        "                ]\n",
        "\n",
        "        # Si despu√©s del filtrado no hay datos, devolver listas vac√≠as\n",
        "        if service_errors.empty:\n",
        "            return [], [], [], \"Porcentaje de Tiquetes Resueltos\"\n",
        "\n",
        "        # Obtener la criticidad disponible (si no se especifica, usar la primera que aparece)\n",
        "        criticalities = service_errors['Criticidad'].unique()\n",
        "\n",
        "        # Si no hay criticidades disponibles, devolver listas vac√≠as\n",
        "        if len(criticalities) == 0:\n",
        "            return [], [], [], \"Porcentaje de Tiquetes Resueltos\"\n",
        "\n",
        "        # Si se proporciona una criticidad espec√≠fica, usarla\n",
        "        if criticality is not None:\n",
        "            if criticality in criticalities:\n",
        "                selected_criticality = criticality\n",
        "            else:\n",
        "                return [], [], [], \"Porcentaje de Tiquetes Resueltos\"\n",
        "        # Permitir al usuario seleccionar la criticidad si hay m√°s de una y no se proporciona una espec√≠fica\n",
        "        elif len(criticalities) > 1 and criticality is None:\n",
        "            selected_criticality = st.sidebar.selectbox(\"Seleccionar Criticidad\", criticalities, key=f\"crit_select_{selected_service}\")\n",
        "        else:\n",
        "            selected_criticality = criticalities[0]\n",
        "\n",
        "        # Filtrar por criticidad\n",
        "        service_errors_by_crit = service_errors[service_errors['Criticidad'] == selected_criticality]\n",
        "\n",
        "        if service_errors_by_crit.empty:\n",
        "            return [], [], [], \"Porcentaje de Tiquetes Resueltos\"\n",
        "\n",
        "        # Calcular el KPI como porcentaje de tiquetes resueltos\n",
        "        kpi_values = []\n",
        "        for i in range(len(service_errors_by_crit)):\n",
        "            total_errors = service_errors_by_crit['Cant_Tiq_Error_Trim'].iloc[i]\n",
        "            closed_errors = service_errors_by_crit['Cant_Tiq_Error_Cerr'].iloc[i]\n",
        "\n",
        "            # Calcular porcentaje de tiquetes resueltos\n",
        "            if total_errors == 0:\n",
        "                pct_resolved = 100  # Si no hay errores, 100% resueltos\n",
        "            else:\n",
        "                pct_resolved = (closed_errors / total_errors) * 100\n",
        "\n",
        "            kpi_values.append(pct_resolved)\n",
        "\n",
        "        # Para el servicio seleccionado, obtener la meta de tiquetes seg√∫n criticidad y a√±o\n",
        "        years = service_errors_by_crit['A√±o'].unique()\n",
        "        meta_values = []\n",
        "        nivel_aceptable = []\n",
        "\n",
        "        for year in years:\n",
        "            if tiquetesConErrores is not None:\n",
        "                # Buscar en el dataframe tiquetesConErrores para obtener los valores de meta\n",
        "                meta_row = tiquetesConErrores[\n",
        "                    (tiquetesConErrores['Criticidad'] == selected_criticality) &\n",
        "                    (tiquetesConErrores['A√±o'] == year)\n",
        "                ]\n",
        "\n",
        "                if not meta_row.empty:\n",
        "                    # FIXED: Convert Meta to percentage (multiply by 100) if it's a ratio\n",
        "                    meta = meta_row['Meta'].values[0]\n",
        "                    if meta <= 1:  # If meta is expressed as a ratio (0-1)\n",
        "                        meta = meta * 100  # Convert to percentage (0-100)\n",
        "                    meta_values.extend([meta] * 4)  # Un valor para cada trimestre\n",
        "\n",
        "                    # Check if 'Nivel_Aceptable' column exists in tiquetesConErrores\n",
        "                    if 'Nivel_Aceptable' in meta_row.columns:\n",
        "                        accept = meta_row['Nivel_Aceptable'].values[0]\n",
        "                        if accept <= 1:  # If acceptance is expressed as a ratio (0-1)\n",
        "                            accept = accept * 100  # Convert to percentage (0-100)\n",
        "                        nivel_aceptable.extend([accept] * 4)\n",
        "                    else:\n",
        "                        # Use default of 80% of meta\n",
        "                        nivel_aceptable.extend([meta * 0.8] * 4)\n",
        "                else:\n",
        "                    # Valores predeterminados si no se encuentra - already in percentage (0-100)\n",
        "                    meta_values.extend([80] * 4)  # 80% resueltos como meta\n",
        "                    nivel_aceptable.extend([64] * 4)  # 64% como aceptable\n",
        "            else:\n",
        "                # Si no se proporciona tiquetesConErrores, usar valores predeterminados - already in percentage (0-100)\n",
        "                meta_values.extend([80] * 4)  # 80% resueltos como meta\n",
        "                nivel_aceptable.extend([64] * 4)  # 64% como aceptable\n",
        "\n",
        "        # Ajustar las listas para que coincidan en longitud con kpi_values\n",
        "        meta_values = meta_values[:len(kpi_values)]\n",
        "        nivel_aceptable = nivel_aceptable[:len(kpi_values)]\n",
        "\n",
        "        return kpi_values, meta_values, nivel_aceptable, f\"Porcentaje de Tiquetes Resueltos ({selected_criticality})\"\n",
        "\n",
        "    # Para otros KPIs, devolver datos vac√≠os\n",
        "    return [], [], [], \"Unknown KPI\"\n",
        "\n",
        "def checkTypeOfKpi(plot_data):\n",
        "    \"\"\"Determine if a KPI is better when higher or lower.\"\"\"\n",
        "    higher_is_better = None\n",
        "    if len(plot_data) > 0:\n",
        "        first_meta = plot_data['Meta'].iloc[0]\n",
        "        first_acceptable = plot_data['Aceptacion'].iloc[0]\n",
        "\n",
        "        if first_meta is not None and first_acceptable is not None:\n",
        "            higher_is_better = first_meta > first_acceptable\n",
        "    return higher_is_better\n",
        "\n",
        "def plotKpiLineChart(plot_data, selected_kpi, selected_service, direction_label, y_axis_label) -> Figure:\n",
        "    \"\"\"Create a line chart for KPI data.\"\"\"\n",
        "    # Create the line plot using Plotly\n",
        "    fig = px.line(plot_data, x='Fecha', y=['KPI', 'Meta', 'Aceptacion'],\n",
        "                title=f\"{selected_kpi} para {selected_service}{direction_label}\",\n",
        "                labels={'value': y_axis_label, 'Fecha': 'Mes', 'variable': 'Metrica'})\n",
        "\n",
        "    # Update line styles for better visualization\n",
        "    fig.update_traces(mode='lines+markers')\n",
        "    fig.update_layout(\n",
        "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "        height=400,\n",
        "        xaxis=dict(\n",
        "            tickformat=\"%Y/%m\"\n",
        "        )\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def createGauge(value, meta, acceptance, title, is_higher_better):\n",
        "    \"\"\"Create a gauge chart for KPI visualization.\"\"\"\n",
        "    if is_higher_better:\n",
        "        # For metrics where higher is better (e.g. availability)\n",
        "        steps = [\n",
        "            {'range': [0, acceptance], 'color': 'red'},\n",
        "            {'range': [acceptance, meta], 'color': 'yellow'},\n",
        "            {'range': [meta, max(110, 1.1 * meta)], 'color': 'green'}\n",
        "        ]\n",
        "        max_val = max(110, 1.1 * meta)  # Ensure max is at least 110 for percentages\n",
        "    else:\n",
        "        # For metrics where lower is better (e.g. response time, error tickets)\n",
        "        steps = [\n",
        "            {'range': [0, meta], 'color': 'green'},\n",
        "            {'range': [meta, acceptance], 'color': 'yellow'},\n",
        "            {'range': [acceptance, 2 * acceptance], 'color': 'red'}\n",
        "        ]\n",
        "        max_val = 2 * acceptance\n",
        "\n",
        "    fig = go.Figure(go.Indicator(\n",
        "        mode=\"gauge+number\",\n",
        "        value=value,\n",
        "        domain={'x': [0, 1], 'y': [0, 1]},\n",
        "        title={'text': title},\n",
        "        gauge={\n",
        "            'axis': {'range': [0, max_val]},\n",
        "            'bar': {'color': \"#1f77b4\"},\n",
        "            'steps': steps,\n",
        "            'threshold': {\n",
        "                'line': {'color': \"black\", 'width': 3},\n",
        "                'thickness': 0.75,\n",
        "                'value': meta\n",
        "            }\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    # Add % sign for percentage metrics\n",
        "    if title == \"Disponibilidad\" or title == \"% Tiquetes Resueltos\":\n",
        "        fig.update_traces(number={'suffix': '%'})\n",
        "\n",
        "    fig.update_layout(height=200, margin=dict(l=30, r=30, t=50, b=30))\n",
        "    return fig\n",
        "\n",
        "\n",
        "def getAllServicesKpi(kpi_name, mediciones, tiempoDeRespuesta, disponibilidad, tiquetesConErrores):\n",
        "    \"\"\"Get KPI values for all services for comparison.\"\"\"\n",
        "    services = mediciones['Aplicaci√≥n'].unique().tolist()\n",
        "    latest_values = []\n",
        "    meta_values = []\n",
        "    acceptance_values = []\n",
        "\n",
        "    # Get the latest date for each service\n",
        "    for service in services:\n",
        "        service_data = mediciones[mediciones['Aplicaci√≥n'] == service].sort_values('Fecha_Inicio_Mes')\n",
        "\n",
        "        if service_data.empty:\n",
        "            continue\n",
        "\n",
        "        # Calculate KPI values for this service\n",
        "        kpi_vals, meta_vals, accept_vals, _ = calculateKpiValues(\n",
        "            service_data, kpi_name, tiempoDeRespuesta, disponibilidad, tiquetesConErrores\n",
        "        )\n",
        "\n",
        "        if kpi_vals and len(kpi_vals) > 0:\n",
        "            latest_values.append((service, kpi_vals[-1]))\n",
        "            meta_values.append(meta_vals[-1] if len(meta_vals) > 0 else None)\n",
        "            acceptance_values.append(accept_vals[-1] if len(accept_vals) > 0 else None)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'Servicio': [item[0] for item in latest_values],\n",
        "        'KPI': [item[1] for item in latest_values],\n",
        "        'Meta': meta_values,\n",
        "        'Aceptacion': acceptance_values\n",
        "    })\n",
        "\n",
        "def getAllServicesTicketsData(service_data, errores, tiquetesConErrores):\n",
        "    \"\"\"Get ticket data for all services.\"\"\"\n",
        "    all_services_data = pd.DataFrame()\n",
        "    services = errores['Aplicaci√≥n'].unique()\n",
        "\n",
        "    for service in services:\n",
        "        # Para cada servicio, obtener todas las criticidades\n",
        "        service_criticalities = errores[errores['Aplicaci√≥n'] == service]['Criticidad'].unique()\n",
        "\n",
        "        for crit in service_criticalities:\n",
        "            # Calcular el KPI para este servicio y criticidad\n",
        "            service_kpi, service_meta, service_accept, _ = calculateTCEWithErroresTable(\n",
        "                service_data, \"Tiquetes con Errores\", errores, service, tiquetesConErrores, crit\n",
        "            )\n",
        "\n",
        "            # Si hay datos, agregar a all_services_data\n",
        "            if len(service_kpi) > 0:\n",
        "                # Usar el √∫ltimo valor como el actual\n",
        "                new_row = pd.DataFrame({\n",
        "                    'Servicio': [f\"{service} ({crit})\"],\n",
        "                    'KPI': [service_kpi[-1]],\n",
        "                    'Meta': [service_meta[-1]],\n",
        "                    'Aceptacion': [service_accept[-1]]\n",
        "                })\n",
        "                all_services_data = pd.concat([all_services_data, new_row], ignore_index=True)\n",
        "\n",
        "    return all_services_data\n",
        "\n",
        "def getBarColor(row, is_higher_better):\n",
        "    \"\"\"Determine color for bar charts based on KPI performance.\"\"\"\n",
        "    kpi_val = row['KPI']\n",
        "    meta_val = row['Meta']\n",
        "    accept_val = row['Aceptacion']\n",
        "\n",
        "    # If meta or acceptance values are missing, return a neutral color\n",
        "    if meta_val is None or accept_val is None:\n",
        "        return 'gray'\n",
        "\n",
        "    if is_higher_better:\n",
        "        # Higher is better (like availability or ticket resolution %)\n",
        "        if kpi_val >= meta_val:\n",
        "            return 'green'\n",
        "        elif kpi_val >= accept_val:\n",
        "            return 'gold'\n",
        "        else:\n",
        "            return 'red'\n",
        "    else:\n",
        "        # Lower is better (like response time)\n",
        "        if kpi_val <= meta_val:\n",
        "            return 'green'\n",
        "        elif kpi_val <= accept_val:\n",
        "            return 'gold'\n",
        "        else:\n",
        "            return 'red'\n",
        "\n",
        "def createBarChart(all_services_data, title, selected_service, direction_label, y_axis_label):\n",
        "    \"\"\"Create bar chart for service comparison.\"\"\"\n",
        "    bar_fig = px.bar(\n",
        "        all_services_data,\n",
        "        x='Servicio',\n",
        "        y='KPI',\n",
        "        height=400,\n",
        "        title=f\"Comparaci√≥n de {title} por servicio{direction_label}\",\n",
        "        labels={'KPI': y_axis_label, 'Servicio': 'Servicio'}\n",
        "    )\n",
        "\n",
        "    # Customize bar colors\n",
        "    bar_fig.update_traces(marker_color=all_services_data['Color'])\n",
        "\n",
        "    # Add reference lines for meta and acceptance thresholds\n",
        "    if not all_services_data.empty:\n",
        "        if all_services_data['Meta'].iloc[0] is not None:\n",
        "            bar_fig.add_shape(\n",
        "                type='line',\n",
        "                x0=-0.5,\n",
        "                x1=len(all_services_data) - 0.5,\n",
        "                y0=all_services_data['Meta'].iloc[0],\n",
        "                y1=all_services_data['Meta'].iloc[0],\n",
        "                line=dict(color='blue', dash='dash', width=2),\n",
        "                name='Meta'\n",
        "            )\n",
        "\n",
        "        if all_services_data['Aceptacion'].iloc[0] is not None:\n",
        "            bar_fig.add_shape(\n",
        "                type='line',\n",
        "                x0=-0.5,\n",
        "                x1=len(all_services_data) - 0.5,\n",
        "                y0=all_services_data['Aceptacion'].iloc[0],\n",
        "                y1=all_services_data['Aceptacion'].iloc[0],\n",
        "                line=dict(color='orange', dash='dot', width=2),\n",
        "                name='Nivel Aceptable'\n",
        "            )\n",
        "\n",
        "    # Highlight the selected service\n",
        "    if selected_service in all_services_data['Servicio'].values:\n",
        "        idx = all_services_data.index[all_services_data['Servicio'] == selected_service].tolist()[0]\n",
        "        bar_fig.add_annotation(\n",
        "            x=selected_service,\n",
        "            y=all_services_data.loc[idx, 'KPI'],\n",
        "            text=\"Seleccionado\",\n",
        "            showarrow=True,\n",
        "            arrowhead=1,\n",
        "            ax=0,\n",
        "            ay=-40\n",
        "        )\n",
        "    return bar_fig\n",
        "\n",
        "def create_plot_data(selected_kpi, service_data, kpi_values, meta_values, nivel_aceptable, errores, selected_service, criticality=None):\n",
        "    \"\"\"Create DataFrame for plotting KPI data.\"\"\"\n",
        "    if len(kpi_values) > 0:\n",
        "        if selected_kpi == \"Tiquetes con Errores\" and 'Fecha' in errores.columns:\n",
        "            service_errors = errores[errores['Aplicaci√≥n'] == selected_service].sort_values('Fecha')\n",
        "\n",
        "            # Filtrar por criticidad si se proporciona\n",
        "            if criticality is not None:\n",
        "                service_errors = service_errors[service_errors['Criticidad'] == criticality]\n",
        "\n",
        "            # Usar las fechas de los errores\n",
        "            plot_data = pd.DataFrame({\n",
        "                'Fecha': service_errors['Fecha'].values[:len(kpi_values)],\n",
        "                'KPI': kpi_values,\n",
        "                'Meta': meta_values,\n",
        "                'Aceptacion': nivel_aceptable\n",
        "            })\n",
        "        else:\n",
        "            # Usar las fechas del service_data\n",
        "            plot_data = pd.DataFrame({\n",
        "                'Fecha': service_data['Fecha_Inicio_Mes'][:len(kpi_values)],\n",
        "                'KPI': kpi_values,\n",
        "                'Meta': meta_values * len(kpi_values) if len(meta_values) == 1 else meta_values,\n",
        "                'Aceptacion': nivel_aceptable * len(kpi_values) if len(nivel_aceptable) == 1 else nivel_aceptable\n",
        "            })\n",
        "    else:\n",
        "        # Crear un DataFrame vac√≠o si no hay datos\n",
        "        plot_data = pd.DataFrame({\n",
        "            'Fecha': [],\n",
        "            'KPI': [],\n",
        "            'Meta': [],\n",
        "            'Aceptacion': []\n",
        "        })\n",
        "\n",
        "    # Eliminar filas con fechas duplicadas (se toma la primera)\n",
        "    plot_data = plot_data.drop_duplicates(subset=['Fecha'])\n",
        "\n",
        "    # Ordenar los datos por fecha\n",
        "    plot_data = plot_data.sort_values('Fecha')\n",
        "\n",
        "    return plot_data\n",
        "\n",
        "def calculateAllKpiValues(service_data, errores, tiempoDeRespuesta, disponibilidad, tiquetesConErrores, selected_service):\n",
        "    \"\"\"Calculate values for all KPIs at once.\"\"\"\n",
        "    # Para Tiempo de Respuesta\n",
        "    tor_service_data = service_data.copy()\n",
        "    ToR = calculateKpiValues(tor_service_data, \"Tiempo Respuesta\", tiempoDeRespuesta, disponibilidad, tiquetesConErrores)\n",
        "    kpi_ToR = ToR[0]\n",
        "    meta_ToR = ToR[1]\n",
        "    acceptance_ToR = ToR[2]\n",
        "\n",
        "    # Para Disponibilidad\n",
        "    disp_service_data = service_data.copy()\n",
        "    Disp = calculateKpiValues(disp_service_data, \"Disponibilidad\", tiempoDeRespuesta, disponibilidad, tiquetesConErrores)\n",
        "    kpi_Disp = Disp[0]\n",
        "    meta_Disp = Disp[1]\n",
        "    acceptance_Disp = Disp[2]\n",
        "\n",
        "    # Para Tiquetes con Errores - pasando tiquetesConErrores como par√°metro\n",
        "    Tiq = calculateTCEWithErroresTable(service_data, \"Tiquetes con Errores\", errores, selected_service, tiquetesConErrores)\n",
        "    kpi_Tiquetes = Tiq[0]\n",
        "    meta_Tiquetes = Tiq[1]\n",
        "    acceptance_Tiquetes = Tiq[2]\n",
        "\n",
        "    return {\n",
        "        'ToR': {\n",
        "            'kpi': kpi_ToR,\n",
        "            'meta': meta_ToR,\n",
        "            'acceptance': acceptance_ToR\n",
        "        },\n",
        "        'Disp': {\n",
        "            'kpi': kpi_Disp,\n",
        "            'meta': meta_Disp,\n",
        "            'acceptance': acceptance_Disp\n",
        "        },\n",
        "        'Tiq': {\n",
        "            'kpi': kpi_Tiquetes,\n",
        "            'meta': meta_Tiquetes,\n",
        "            'acceptance': acceptance_Tiquetes\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKuKIR_8NgZ4"
      },
      "source": [
        "# 4. Crear UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dE_TzcoNv4F",
        "outputId": "6fc18632-bd3f-4eb7-f8d5-31b223930084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from utils import (\n",
        "    loadData, preprocessErrores, setupFilters, calculateAllKpiValues, create_plot_data,\n",
        "    checkTypeOfKpi, plotKpiLineChart, createGauge, getAllServicesKpi, getAllServicesTicketsData,\n",
        "    createBarChart, getBarColor, prepareDataTable, getSemaphore\n",
        ")\n",
        "\n",
        "# Configurar la p√°gina de Streamlit\n",
        "st.set_page_config(\n",
        "    page_title=\"Dashboard | KPIs\",\n",
        "    page_icon=\"üìä\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Cargar y preprocesar los datos\n",
        "mediciones, tiempoDeRespuesta, disponibilidad, tiquetesConErrores, errores = loadData()\n",
        "errores = preprocessErrores(errores)\n",
        "\n",
        "# Configurar filtros y obtener datos filtrados\n",
        "selected_service, selected_kpi, service_data = setupFilters(mediciones)\n",
        "\n",
        "# Calcular valores para todos los KPIs independientemente del KPI seleccionado\n",
        "all_kpi_values = calculateAllKpiValues(\n",
        "    service_data, errores, tiempoDeRespuesta, disponibilidad, tiquetesConErrores, selected_service\n",
        ")\n",
        "\n",
        "# Obtener los valores de KPI para cada tipo\n",
        "kpi_ToR = all_kpi_values['ToR']['kpi']\n",
        "meta_ToR = all_kpi_values['ToR']['meta']\n",
        "acceptance_ToR = all_kpi_values['ToR']['acceptance']\n",
        "\n",
        "kpi_Disp = all_kpi_values['Disp']['kpi']\n",
        "meta_Disp = all_kpi_values['Disp']['meta']\n",
        "acceptance_Disp = all_kpi_values['Disp']['acceptance']\n",
        "\n",
        "kpi_Tiquetes = all_kpi_values['Tiq']['kpi']\n",
        "meta_Tiquetes = all_kpi_values['Tiq']['meta']\n",
        "acceptance_Tiquetes = all_kpi_values['Tiq']['acceptance']\n",
        "\n",
        "# Crear el DataFrame para la gr√°fica para el KPI seleccionado\n",
        "plot_data = create_plot_data(\n",
        "    selected_kpi, service_data, kpi_ToR if selected_kpi == \"Tiempo Respuesta\" else kpi_Disp if selected_kpi == \"Disponibilidad\" else kpi_Tiquetes,\n",
        "    meta_ToR if selected_kpi == \"Tiempo Respuesta\" else meta_Disp if selected_kpi == \"Disponibilidad\" else meta_Tiquetes,\n",
        "    acceptance_ToR if selected_kpi == \"Tiempo Respuesta\" else acceptance_Disp if selected_kpi == \"Disponibilidad\" else acceptance_Tiquetes,\n",
        "    errores, selected_service\n",
        ")\n",
        "\n",
        "# Determinar si el KPI es mejor cuando es m√°s alto o m√°s bajo\n",
        "is_higher_is_better = selected_kpi != \"Tiempo Respuesta\"  # Forced logic: ToR is lower-better, others are higher-better\n",
        "\n",
        "# Crear la etiqueta de tipo de KPI\n",
        "direction_label = \" (M√°s es mejor)\" if is_higher_is_better else \" (Menos es mejor)\"\n",
        "\n",
        "# Crear layout de columnas para el dashboard\n",
        "main_col, metrics_col = st.columns([7, 2])\n",
        "\n",
        "# Columna principal para gr√°ficos y m√©tricas principales\n",
        "with main_col:\n",
        "    # Mostrar estado actual de los KPI contra el valor anterior\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # Metricas de Tiempo de Respuesta\n",
        "    if len(kpi_ToR) >= 2:\n",
        "        tor_diff = kpi_ToR[-1] - kpi_ToR[-2]\n",
        "        col1.metric(\n",
        "            f\"Tiempo de Respuesta (s)\",\n",
        "            f\"{kpi_ToR[-1]:.2f}s\",\n",
        "            f\"{tor_diff:.2f}s\",\n",
        "            delta_color=\"inverse\"\n",
        "        )\n",
        "    else:\n",
        "        col1.metric(f\"Tiempo de Respuesta (s)\", \"N/A\", \"0s\", delta_color=\"inverse\")\n",
        "\n",
        "    # Metricas de Disponibilidad\n",
        "    if len(kpi_Disp) >= 2:\n",
        "        disp_diff = kpi_Disp[-1] - kpi_Disp[-2]\n",
        "        col2.metric(\n",
        "            f\"Disponibilidad (%)\",\n",
        "            f\"{kpi_Disp[-1]:.2f}%\",\n",
        "            f\"{disp_diff:.2f}%\",\n",
        "            delta_color=\"normal\"\n",
        "        )\n",
        "    else:\n",
        "        col2.metric(f\"Disponibilidad (%)\", \"N/A\", \"0%\", delta_color=\"normal\")\n",
        "\n",
        "    # Metricas de Tiquetes Resueltos\n",
        "    if len(kpi_Tiquetes) >= 2:\n",
        "        tiq_diff = kpi_Tiquetes[-1] - kpi_Tiquetes[-2]\n",
        "        col3.metric(\n",
        "            f\"Tiquetes Resueltos (%)\",\n",
        "            f\"{kpi_Tiquetes[-1]:.2f}%\",\n",
        "            f\"{tiq_diff:.2f}%\",\n",
        "            delta_color=\"normal\"\n",
        "        )\n",
        "    else:\n",
        "        col3.metric(f\"Tiquetes Resueltos (%)\", \"N/A\", \"0%\", delta_color=\"normal\")\n",
        "\n",
        "    # Gr√°fica de l√≠nea para el KPI seleccionado con datos historicos\n",
        "    if not plot_data.empty:\n",
        "        y_axis_label = \"Tiempo de Respuesta (s)\" if selected_kpi == \"Tiempo Respuesta\" else \"Disponibilidad (%)\" if selected_kpi == \"Disponibilidad\" else \"Porcentaje de Tiquetes Resueltos\"\n",
        "        line_chart = plotKpiLineChart(plot_data, selected_kpi, selected_service, direction_label, y_axis_label)\n",
        "        st.plotly_chart(line_chart, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No hay datos suficientes para mostrar la gr√°fica.\")\n",
        "\n",
        "# Columna de m√©tricas adicionales\n",
        "with metrics_col:\n",
        "    st.subheader(\"Medidores de KPI\")\n",
        "\n",
        "    # Velocimetro para Tiempo de Respuesta\n",
        "    if len(kpi_ToR) > 0:\n",
        "        tor_gauge = createGauge(kpi_ToR[-1], meta_ToR[-1], acceptance_ToR[-1], \"Tiempo de Respuesta\", False)\n",
        "        st.plotly_chart(tor_gauge, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No hay datos para el medidor de Tiempo de Respuesta.\")\n",
        "\n",
        "    # Velocimetro para Disponibilidad\n",
        "    if len(kpi_Disp) > 0:\n",
        "        disp_gauge = createGauge(kpi_Disp[-1], meta_Disp[-1], acceptance_Disp[-1], \"Disponibilidad\", True)\n",
        "        st.plotly_chart(disp_gauge, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No hay datos para el medidor de Disponibilidad.\")\n",
        "\n",
        "    # Velocimetro para Tiquetes Resueltos\n",
        "    if len(kpi_Tiquetes) > 0:\n",
        "        tiq_gauge = createGauge(kpi_Tiquetes[-1], meta_Tiquetes[-1], acceptance_Tiquetes[-1], \"Tiquetes Resueltos\", True)\n",
        "        st.plotly_chart(tiq_gauge, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No hay datos para el medidor de Tiquetes Resueltos.\")\n",
        "\n",
        "# Comparaci√≥n entre servicios\n",
        "st.subheader(\"Comparaci√≥n entre Servicios\")\n",
        "if selected_kpi == \"Tiquetes con Errores\":\n",
        "    all_services_data = getAllServicesTicketsData(service_data, errores, tiquetesConErrores)\n",
        "else:\n",
        "    all_services_data = getAllServicesKpi(selected_kpi, mediciones, tiempoDeRespuesta, disponibilidad, tiquetesConErrores)\n",
        "\n",
        "if not all_services_data.empty:\n",
        "    is_higher_better = selected_kpi != \"Tiempo Respuesta\"\n",
        "\n",
        "    # Aplicar el color a las barras con base a el cumplimiento de la meta\n",
        "    all_services_data['Color'] = all_services_data.apply(\n",
        "        lambda row: getBarColor(row, is_higher_better),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Crear y mostrar la gr√°fica de barras\n",
        "    bar_chart = createBarChart(all_services_data, selected_kpi, selected_service, direction_label, y_axis_label)\n",
        "    st.plotly_chart(bar_chart, use_container_width=True)\n",
        "\n",
        "    # Secci√≥n de datos por servicio\n",
        "    st.subheader(\"Datos por Servicio\")\n",
        "\n",
        "    # Crear un datafrmame para mostrar los datos de todos los servicios\n",
        "    display_data = all_services_data.copy()\n",
        "    if 'Color' in display_data.columns:\n",
        "        display_data = display_data.drop(columns=['Color'])\n",
        "\n",
        "    # Aplicar la funcion para determinar el estado de cada servicio\n",
        "    display_data['Estado'] = display_data.apply(\n",
        "        lambda row: getSemaphore(row, is_higher_better),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Dar formato de porcentaje a los valores de KPI, Meta y Aceptacion\n",
        "    if selected_kpi != \"Tiempo Respuesta\":\n",
        "        display_data['KPI'] = display_data['KPI'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "        display_data['Meta'] = display_data['Meta'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "        display_data['Aceptacion'] = display_data['Aceptacion'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "    else:\n",
        "        display_data['KPI'] = display_data['KPI'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "        display_data['Meta'] = display_data['Meta'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "        display_data['Aceptacion'] = display_data['Aceptacion'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "\n",
        "    # Mostrar la tabla con los sem√°foros\n",
        "    with st.expander(\"Comparaci√≥n entre servicios\", expanded=True):\n",
        "        st.dataframe(display_data, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"No hay datos suficientes para la comparaci√≥n entre servicios.\")\n",
        "\n",
        "# Tabla detallada del servicio seleccionado\n",
        "if not plot_data.empty:\n",
        "    # Preparar los datos para la tabla\n",
        "    service_table_data = prepareDataTable(plot_data, is_higher_better)\n",
        "\n",
        "    # Dar formato con base en el tipo de KPI\n",
        "    if selected_kpi != \"Tiempo Respuesta\":\n",
        "        service_table_data['KPI'] = service_table_data['KPI'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "        service_table_data['Meta'] = service_table_data['Meta'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "        service_table_data['Aceptacion'] = service_table_data['Aceptacion'].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else \"N/A\")\n",
        "    else:\n",
        "        service_table_data['KPI'] = service_table_data['KPI'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "        service_table_data['Meta'] = service_table_data['Meta'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "        service_table_data['Aceptacion'] = service_table_data['Aceptacion'].apply(lambda x: f\"{x:.2f}s\" if pd.notnull(x) else \"N/A\")\n",
        "\n",
        "    # Mostrar la tabla con los datos del servicio seleccionado\n",
        "    with st.expander(\"Datos historicos del servicio seleccionado\", expanded=True):\n",
        "        st.dataframe(service_table_data, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"No hay datos suficientes para mostrar la tabla del servicio seleccionado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEpZ8UzGOutW"
      },
      "source": [
        "# 5. Obtener IP\n",
        "> Utilizar como contrase√±a de la url en el proximo paso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjBjDJrYOx1E",
        "outputId": "3cb8a0b5-1807-430c-d851-b2ba8135f33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104.155.213.97\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ASD8X2O_Fp"
      },
      "source": [
        "# 6. Exponer tunel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUuts_kYPBLp",
        "outputId": "a08c416f-ee49-48dc-81c0-d142ab2cbca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "your url is: https://tough-lizards-repair.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.155.213.97:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}